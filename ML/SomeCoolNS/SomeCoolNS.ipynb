{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#本机器学习代码将输出各节点权重值和最后各个样本的损失\n",
    "#陈逍风编写\n",
    "# O-----O----O\\\n",
    "#   \\ /        \\\n",
    "#    X          --O---O\n",
    "#   / \\        /\n",
    "# O-----O----O/\n",
    "# Layer1    Layer2\n",
    "#该神经网络由两层构成,以随机反向传播训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas=np.asarray([[0,1,0],[1,1,0],[1,0,0],[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "def dsigmoid(x):\n",
    "    return x*(1-x)\n",
    "def Cost(Ans,ExceptAns):\n",
    "    return (ExceptAns-Ans)**2/2\n",
    "def dCost(Ans,ExceptAns):\n",
    "    return -1*(ExceptAns-Ans)\n",
    "def MultiMat(m1,m2):\n",
    "    return [m1[0]*m2[0],m1[1]*m2[1]]\n",
    "def DotMulti(m1,m2):\n",
    "    return m1[0]*m2[0]+m1[1]*m2[1]\n",
    "\n",
    "Layer1=[np.asarray([0.1,0.3,0.2,0.4]).reshape(2,2),np.asarray([0.7,0.8])]\n",
    "Layer2=[np.asarray([0.5,0.6]),np.asarray([0.9])]\n",
    "cost=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(array([[-0.0018184 , -0.00165529],\n",
       "         [-0.0018184 , -0.00165529]]),\n",
       "  array([-0.0018184 , -0.00165529])),\n",
       " (array([-0.01352262, -0.01512293]), array([-0.01849732]))]"
      ]
     },
     "metadata": {},
     "execution_count": 492
    }
   ],
   "source": [
    "def CalculateLearn(X,ExceptAns,costO=[0]):\n",
    "    Z1 = np.asarray(list(map(sigmoid,np.dot(X,Layer1[0])+Layer1[1]))) #第一层的输出\n",
    "    Z2 = (sigmoid(DotMulti(Z1,Layer2[0])+Layer2[1]))[0]                   #第二层的输出\n",
    "    #print(f\"Z1={Z1}\")\n",
    "    #print(f\"Z2={Z2}\")\n",
    "    cost=Cost(Z2,ExceptAns)                                             #损失\n",
    "    costO[0]=cost\n",
    "    #print(f\"cost={cost}\")\n",
    "\n",
    "    dZ2=dCost(Z2,ExceptAns)*dsigmoid(Z2)                            #第二层的偏导\n",
    "    dLayer2=np.asarray([dZ2*Z1[0],dZ2*Z1[1]]),np.asarray([dZ2])   #第二层参数的偏导\n",
    "\n",
    "    dZ1=MultiMat([dZ2*Layer2[0][0],dZ2*Layer2[0][1]] , [dsigmoid(Z1[0]),dsigmoid(Z1[1])])\n",
    "    dLayer1=np.asarray([ [dZ1[0]*X[0],dZ1[1]*X[0]] ,[dZ1[0]*X[1],dZ1[1]*X[1]] ]),np.asarray(dZ1)  #第一层参数的偏导\n",
    "    #print(f\"最后的改变值={dZ2}\")\n",
    "    dLayer=[dLayer1,dLayer2]                                                    #格式[[第一层扭转],[第一层平移]],[第二层扭转,第二层平移]\n",
    "    return dLayer\n",
    "\n",
    "#测试\n",
    "CalculateLearn(datas[1][0:2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[array([[-6.51124968, -3.10338865],\n       [-6.51766028, -3.0968805 ]]), array([3.0763317 , 8.90804628])]\n[array([10.99158964, -9.86231017]), array([4.1453742])]\n1.1298026467925583e-05\n"
     ]
    }
   ],
   "source": [
    "learntimes=50000    #学习次数\n",
    "fc=0.5              #学习率\n",
    "cost=[0.1]\n",
    "for i in range(learntimes):\n",
    "    index = random.randint(0,3)\n",
    "    d=CalculateLearn(datas[index][0:2],datas[index][2],cost)\n",
    "    Layer1[0] = Layer1[0] - d[0][0]*fc\n",
    "    Layer1[1] = Layer1[1] - d[0][1]*fc\n",
    "    Layer2[0] = Layer2[0] - d[1][0]*fc\n",
    "    Layer2[1] = Layer2[1] - d[1][1]*fc\n",
    "    #print(Calculate(datas[index][0:2]))\n",
    "print(Layer1)\n",
    "print(Layer2)\n",
    "print(cost[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#以上为学习段    以下为验证段#\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate(X):\n",
    "    Z1 = np.asarray(list(map(sigmoid,np.dot(X,Layer1[0])+Layer1[1]))) #第一层的输出\n",
    "    Z2 = (sigmoid(DotMulti(Z1,Layer2[0])+Layer2[1]))[0]                   #第二层的输出\n",
    "    return Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.004742466057624196\n0.0060606415373605374\n0.004753412599673606\n0.008233122415125527\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(abs(Calculate(datas[i][0:2])-datas[i][2]))"
   ]
  }
 ]
}